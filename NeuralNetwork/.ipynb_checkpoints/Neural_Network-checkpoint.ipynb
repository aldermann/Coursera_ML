{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1Ngs1jNdCda6",
    "outputId": "05adec8f-a6de-4e46-dbe5-92b89477a8d6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKnUkrWbCda9"
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data.pkz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28PvEG_RCdbD"
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "layerLengths = [784, 15, 10]\n",
    "layerCounts = len(layerLengths)\n",
    "alpha = 1\n",
    "num_iters = 100\n",
    "epsilon = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48HyywnCCdbF"
   },
   "outputs": [],
   "source": [
    "def generateY(y):\n",
    "    m = y.shape[0]\n",
    "    Y = np.zeros((layerLengths[-1], m))\n",
    "    for i in range(m):\n",
    "        Y[y.iloc[i], i] = 1\n",
    "    return Y\n",
    "\n",
    "def featureNormalize(X, mu=None, sigma=None):\n",
    "    if mu is None:\n",
    "        mu = np.mean(X.values)\n",
    "    if sigma is None:\n",
    "        sigma = np.std(X.values)\n",
    "    return ((X - mu) / sigma, mu, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "uJvAT6edCdbH",
    "outputId": "854cb86b-e887-4d5d-cc1b-df79b69008d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.408911169825075 78.677739760763\n"
     ]
    }
   ],
   "source": [
    "data_X = data.loc[:, \"pixel0\":]\n",
    "data_y = data.loc[:, \"label\"]\n",
    "\n",
    "data_X, mu, sigma = featureNormalize(data_X)\n",
    "print(mu, sigma)\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.2)\n",
    "\n",
    "train_X = train_X.T\n",
    "train_y = train_y.T\n",
    "test_X = test_X.T\n",
    "test_y = test_y.T\n",
    "\n",
    "test_Y = generateY(test_y)\n",
    "train_Y = generateY(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeiQkVdoCdbJ"
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def sigmoid (A):\n",
    "    return 1 / (1 + np.exp(-A))\n",
    "\n",
    "def prependWithValues(A, v = 1):\n",
    "    return np.insert(A, 0, [v], axis=0)\n",
    "\n",
    "def updateTheta(theta, delta):\n",
    "    for i in range(layerCounts - 1):\n",
    "        theta[i] -= delta[i] * alpha\n",
    "    return theta\n",
    "        \n",
    "def initRandomTheta():\n",
    "    theta = []\n",
    "    for i in range(layerCounts - 1):\n",
    "        l = layerLengths[i]\n",
    "        nl = layerLengths[i + 1]\n",
    "        theta.append(np.random.rand(nl, l + 1) * 2 - 1)\n",
    "    return theta\n",
    "        \n",
    "def flattenTheta(theta):\n",
    "    res = np.empty((0, 0))\n",
    "    for t in theta:\n",
    "        ft = t.flatten()\n",
    "        res = np.append(res, ft)\n",
    "    return res\n",
    "\n",
    "def reshapeTheta(flatten_theta):\n",
    "    theta = []\n",
    "    s = 0\n",
    "    for i in range(layerCounts - 1):\n",
    "        w = layerLengths[i] + 1\n",
    "        h = layerLengths[i + 1]\n",
    "        segment = flatten_theta[s:s+w*h]\n",
    "        theta.append(segment.reshape(h, w))\n",
    "        s += w * h\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECgbtkvtCdbL"
   },
   "outputs": [],
   "source": [
    "def forwardPropagation(X, theta):\n",
    "    activations = [None] * layerCounts\n",
    "    activations[0] = X.values\n",
    "    for i in range(1, layerCounts):\n",
    "        # insert bias unit into evaluation\n",
    "        a = prependWithValues(activations[i - 1])\n",
    "        activations[i] = sigmoid(theta[i - 1] @ a)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lqd166PJCdbQ"
   },
   "outputs": [],
   "source": [
    "def cost(X, Y, theta, lmbd=0):\n",
    "    m = X.shape[1]\n",
    "    activations = forwardPropagation(X, theta)\n",
    "    h = activations[-1]\n",
    "    reg_theta = [t[1:,:] for t in theta]\n",
    "    reg_term = sum([np.sum((np.square(t))) for t in reg_theta]) * lmbd / (2 * m)\n",
    "    J = np.sum(Y * np.log(h) + (1 - Y) * np.log(1 - h)) * (-1 / m) \n",
    "    return [J, activations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7dZwE8tJCdbS"
   },
   "outputs": [],
   "source": [
    "def backwardPropagation(activations, Y, theta, lmbd=0):\n",
    "    delta = []\n",
    "    A = []\n",
    "    YY = prependWithValues(Y)\n",
    "    for t in theta:\n",
    "        delta.append(np.zeros(t.shape))\n",
    "    for i in range(len(activations)):\n",
    "        A.append(prependWithValues(activations[i]))\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    for caseId in range(m):\n",
    "        act = []\n",
    "        d = [None] * layerCounts\n",
    "        y = YY[:, caseId]\n",
    "        for i in range(layerCounts):\n",
    "            act.append(A[i][:, caseId])\n",
    "        d[-1] = act[-1] - y\n",
    "        for i in range(layerCounts - 2, 0, -1):\n",
    "            d[i] = theta[i].T @ d[i + 1][1:] * act[i] * (1 - act[i])\n",
    "        for i in range(layerCounts - 1):\n",
    "            delta[i] += d[i + 1][1:, None] @ act[i].reshape(1, len(act[i]))\n",
    "    reg_theta = [t.copy() for t in theta]\n",
    "    for i in range(layerCounts - 1):\n",
    "        reg_theta[i][0, :] = [0]\n",
    "        reg_theta[i] *= lmbd\n",
    "    for i in range(layerCounts - 1):\n",
    "        delta[i] = (delta[i] + reg_theta[i]) / m\n",
    "    \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IfDrxgkCdbW"
   },
   "outputs": [],
   "source": [
    "def estimateGradient(X, Y, theta):\n",
    "    gradients = []\n",
    "    fTheta = flattenTheta(theta)\n",
    "    p = np.zeros(fTheta.shape)\n",
    "    for i in range(len(fTheta)):\n",
    "        p[i] = epsilon\n",
    "        ht = reshapeTheta(fTheta + p)\n",
    "        lt = reshapeTheta(fTheta - p)\n",
    "        g = (cost(X, Y, ht)[0] - cost(X, Y, lt)[0]) / (2 * epsilon)\n",
    "        gradients.append(g)\n",
    "        p[i] = 0\n",
    "    return np.array(gradients)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Q2Hn5fKCdbY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest difference between backprop gradient and estimated gradient:  1.5345019921397807e-08\n"
     ]
    }
   ],
   "source": [
    "# gradient check\n",
    "gtt = initRandomTheta()\n",
    "id = [1, 2]\n",
    "gtX = test_X.iloc[:, id]\n",
    "gtY = test_Y[:, id]\n",
    "eg = estimateGradient(gtX, gtY, gtt)\n",
    "act = forwardPropagation(gtX, gtt)\n",
    "g = backwardPropagation(act, gtY, gtt)\n",
    "print(\"Highest difference between backprop gradient and estimated gradient: \",  max(flattenTheta(g) - eg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "id": "g3I0Hnc4Cdbe",
    "outputId": "590c7a45-8a3b-4e63-92bc-006fe375d377"
   },
   "outputs": [],
   "source": [
    "# train using whole batched gradient descent\n",
    "def gradientDescent(X, Y, num_epoch=100, alpha=1, theta=None, print_cost=False, lmbd=1):\n",
    "    if theta is None:\n",
    "        theta = initRandomTheta()\n",
    "    act = []\n",
    "    costHistory = []\n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"Training epoch: \", epoch)\n",
    "        c, act = cost(X, Y, theta, lmbd)\n",
    "        gradient = backwardPropagation(act, Y, theta, lmbd)\n",
    "        theta = updateTheta(theta, gradient)\n",
    "        costHistory.append(c)\n",
    "        if print_cost:\n",
    "            print(c)\n",
    "        if costHistory[-1] - c >= 1e-7:\n",
    "            break\n",
    "    np.save(\"weight.npy\",theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using mini batch gradient descent\n",
    "def getBatch(X, Y, batchSize):\n",
    "    m = X.shape[1]\n",
    "    idx = np.random.permutation(m)\n",
    "    X, Y = X.iloc[:, idx], Y[:, idx]\n",
    "    l = 0\n",
    "    while True:\n",
    "        h = min(l + batchSize, m)\n",
    "        yield (X.iloc[:, l: h], Y[:, l: h])\n",
    "        if h == m:\n",
    "            break\n",
    "        l = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniBatchGradientDescent(X, Y, num_epoch=50, alpha=1, theta=None, print_cost=False, batch_size=200, lmbd=1):\n",
    "    if theta is None:\n",
    "        theta = initRandomTheta()\n",
    "    act = []\n",
    "    costHistory = []\n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"Training epoch: \", epoch)\n",
    "        for b_X, b_Y in getBatch(X, Y, batch_size):\n",
    "            c, act = cost(b_X, b_Y, theta, lmbd)\n",
    "            gradient = backwardPropagation(act, b_Y, theta, lmbd)\n",
    "            theta = updateTheta(theta, gradient)\n",
    "            costHistory.append(c)\n",
    "            if print_cost:\n",
    "                print(c)\n",
    "    np.save(\"weight.npy\",theta)\n",
    "    plt.plot(costHistory)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:  0\n",
      "Training epoch:  1\n",
      "Training epoch:  2\n",
      "Training epoch:  3\n",
      "Training epoch:  4\n",
      "Training epoch:  5\n",
      "Training epoch:  6\n",
      "Training epoch:  7\n",
      "Training epoch:  8\n",
      "Training epoch:  9\n",
      "Final cost:  0.21740476364174663\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "%matplotlib inline\n",
    "nn_theta = miniBatchGradientDescent(train_X, train_Y, num_epoch=50, alpha=3, lmbd=1, theta=old_theta)\n",
    "# nn_theta = gradientDescent(train_X, train_Y, num_epoch=50, alpha=2, lmbd=5)\n",
    "print(\"Final cost: \", cost(train_X, train_Y, nn_theta)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jf_oZWjBCdbg"
   },
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    activations = forwardPropagation(X, theta)\n",
    "    h = activations[-1]\n",
    "    return (np.argmax(h, axis=0), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "uDEYFSKiCdbi",
    "outputId": "7100f7aa-b775-4667-f458-1f7280de1dad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is number : 5\n",
      "Prediction probabilities:  [0.    0.    0.    0.006 0.    0.835 0.    0.    0.002 0.112]\n"
     ]
    }
   ],
   "source": [
    "id = np.random.randint(0, test_X.shape[1])\n",
    "tX = test_X.iloc[:, id]\n",
    "tY = test_Y[:, id]\n",
    "pixels = tX.values.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "res, prob = predict(tX, nn_theta)\n",
    "print(\"This is number :\", res)\n",
    "print(\"Prediction probabilities: \", np.around(prob, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted  7762  in  8400  times\n",
      "Accuracy:  92.4047619047619 %\n"
     ]
    }
   ],
   "source": [
    "eval_X = test_X.iloc[:,]\n",
    "eval_y = test_y[:]\n",
    "res, _ = predict(eval_X, nn_theta)\n",
    "correct_count = np.sum(res == eval_y)\n",
    "total_count = eval_X.shape[1] \n",
    "print(\"Correctly predicted \", correct_count , \" in \", total_count, \" times\")\n",
    "print(\"Accuracy: \", correct_count / total_count * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_X = eval_X.loc[:, res != eval_y]\n",
    "pixels = wrong_X.iloc[:,np.random.randint(0, len(wrong_X))].values.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Neural Network.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
